{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9e7dfbe",
   "metadata": {},
   "source": [
    "## Analysis and Cleaning of Datasets\n",
    "\n",
    "### Introduction\n",
    "\n",
    "Dataset is driving tests; it includes cities and months tests were done, seperated into female and male, adding them all at the end of the row, and the overall total of the year at the bottom of the city before a new one is introduced.\n",
    "\n",
    "Initially the dataset looked pretty boring, too much information to process at once, questions at the start were pretty basic due to it.\n",
    "\n",
    "### Aims\n",
    "\n",
    "- How can we use driving tests to help control/predict automatic/manual car productions:\n",
    "    - Electric car production increase as supporting evidence (electric cars are automatic)\n",
    "\n",
    "### Ethics\n",
    "\n",
    "- Potential personal information contraversies;\n",
    "- The idea of seoerating total tests into male and female, possibly not including anything in between;\n",
    "- AI trying to change certain data to increase the possible outcome, due to errors in programming\n",
    "- Certain companies could see the research as a challenge or incentive due to it researching the increase of electric cars, which require electricity and not fuel.\n",
    "- News outlets could use research to \"manipulate\" public image in the way they lean towards\n",
    "\n",
    "### Data Transformation and Cleaning\n",
    "\n",
    "Manually cleaned data, not very efficient, however got to see the data \"personally\" allowing faults to be seen, such as missing data and data inconsistencies.\n",
    "Inconsistencies include:\n",
    "- Dates varying from month-year to month-month-year in some cases\n",
    "- Missing years in some excel sheets\n",
    "- Some cities missing data/have some data but not all\n",
    "- Table formats are inconsistent, some having empty columns to separate certain columns, some rows were in bold, but others of similar value were not\n",
    "Could create an algorithm to filter through every excel sheet if wanted to, but wouldn't be able to see the errors or inconsistencies early enough (before programming)\n",
    "Data format being used is CSV due to simplicity and ease of use.\n",
    "\n",
    "### Methods\n",
    "\n",
    "Statistics:\n",
    "- Increase of automatic driving tests compared to manual over the years\n",
    "- Potential increase hypothesis using external data such as electric car increase or the national electric car law to be introduced in 2030/2050\n",
    "- Means of values\n",
    "- Skewness, Kurtosis, Modality\n",
    "- Correlation between electric car production and automatic car increase (is correlation = cause?)\n",
    "- Statistical test: Will the increase of automatic car driving lessons increase even more drastically in the future compared to as it is now?\n",
    "\n",
    "Visualisations:\n",
    "- Bar chart showcasing manual car tests over the years and automatic car test over the years\n",
    "- Line chart of electric car production increase in the uk\n",
    "\n",
    "### Statistics\n",
    "\n",
    "Statistics Checklist:\n",
    "- Increase o fautomatic driving tests compared to manual over the years\n",
    "- Potential increase hypothesis using external data such as electric car increase or the national electric car law to be introduced in 2030/2050\n",
    "- Means of values\n",
    "- Skewness, Kurtosis, Modality\n",
    "- Correlation between electric car production and automatic car increase (is correlation = cause)\n",
    "- Statistical test: Will the increase of automatic car driving lessons increase even more drastically in the future compared to as it is now, and can we use that to predict electric/manual car productions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ed18f8",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8906a9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all imports are here\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib as mpl\n",
    "import statistics as stat \n",
    "from scipy import stats\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22245d7",
   "metadata": {},
   "source": [
    "#### Plot Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1b1aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_size: tuple[int] = (10, 5)\n",
    "header_size: int = 18\n",
    "labels_size: int = 12\n",
    "background_colour: str = '#E9EED9'\n",
    "plot_colour_1: str = '#4048BF'\n",
    "plot_colour_2: str = '#E97451'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0d9ceb",
   "metadata": {},
   "source": [
    "#### Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fde7a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in all the needed csv files\n",
    "automatic_national_totals = pd.read_csv('Spreadsheets/Automatic_Tests/National_Totals.csv')\n",
    "driving_national_totals = pd.read_csv('Spreadsheets/Driving_Tests/National_Totals.csv')\n",
    "electric_car_totals = pd.read_csv('Spreadsheets/Electric_Car_Production/End_of_Quarter_Totals.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed834dcb",
   "metadata": {},
   "source": [
    "#### Reusable Statistics Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdb1e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All reusable functions used to calculate the various statistics used for graphs\n",
    "\n",
    "def calculate_spearmans(list1: list[float], list2: list[float]) -> None:\n",
    "    \"\"\"\n",
    "    Calculates the Spearman's correlation coefficient.\n",
    "\n",
    "    This function takes two lists and calculates the Spearman's correlation coefficient, represented as \"R\" and \"P\".\n",
    "    The results are printed in the terminal with four decimal points.\n",
    "    \"In statistics, Spearman's rank correlation coefficient or Spearman's ρ is a number ranging from -1 to 1 that indicates how strongly two sets of ranks are correlated.\"\n",
    "    Note to self: Write wikipedia reference properly here\n",
    "\n",
    "    :param list1: A list to check correlation with\n",
    "    :type list1: list[float]\n",
    "    :param list2: A list to check correlation to\n",
    "    :type list2: list[float]\n",
    "\n",
    "    :Example:\n",
    "    >>> calculate_spearmans(thousands_automatic_conducted, electric_licensed)\n",
    "    \"Spearman R = 0.7455\n",
    "    Spearman P = 0.0085\"\n",
    "    \"\"\"\n",
    "\n",
    "    r, p = stats.spearmanr(list1, list2)\n",
    "    print(f\"Spearman R = {r:.4f}\\nSpearman P = {p:,4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
